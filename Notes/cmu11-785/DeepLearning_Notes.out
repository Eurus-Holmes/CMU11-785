\BOOKMARK [1][-]{section.1}{Deep learning Theory}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{MLP: Intuitive Understanding}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{MLP: Theoretical Proof}{section.1}% 3
\BOOKMARK [1][-]{section.2}{Neural Networks: Part 1}{}% 4
\BOOKMARK [2][-]{subsection.2.1}{Basic Concepts And Theoretical Foundations}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.2}{Gradient Descent Theory and Objective Function}{section.2}% 6
\BOOKMARK [1][-]{section.3}{Neural Networks: Part 2}{}% 7
\BOOKMARK [2][-]{subsection.3.1}{Backward Propagation Theory And Convergence}{section.3}% 8
\BOOKMARK [1][-]{section.4}{Neural Network Training}{}% 9
\BOOKMARK [2][-]{subsection.4.1}{Concept combing}{section.4}% 10
\BOOKMARK [2][-]{subsection.4.2}{Three ways to reduce the gradient}{section.4}% 11
\BOOKMARK [2][-]{subsection.4.3}{Several methods of optimizing the algorithm:}{section.4}% 12
\BOOKMARK [2][-]{subsection.4.4}{Generalization strategy}{section.4}% 13
\BOOKMARK [2][-]{subsection.4.5}{Training skills}{section.4}% 14
\BOOKMARK [3][-]{subsubsection.4.5.1}{Divergence Evaluation Function}{subsection.4.5}% 15
\BOOKMARK [3][-]{subsubsection.4.5.2}{Batch Normalization}{subsection.4.5}% 16
\BOOKMARK [3][-]{subsubsection.4.5.3}{Other Tips}{subsection.4.5}% 17
\BOOKMARK [1][-]{section.5}{Convolutional Nerual Networks \(CNN\)}{}% 18
\BOOKMARK [2][-]{subsection.5.1}{Different layers in CNN}{section.5}% 19
\BOOKMARK [3][-]{subsubsection.5.1.1}{Convolution Layer}{subsection.5.1}% 20
\BOOKMARK [3][-]{subsubsection.5.1.2}{Pooling Layer}{subsection.5.1}% 21
\BOOKMARK [2][-]{subsection.5.2}{Multi-class learning}{section.5}% 22
\BOOKMARK [3][-]{subsubsection.5.2.1}{Derivation}{subsection.5.2}% 23
\BOOKMARK [3][-]{subsubsection.5.2.2}{Notes}{subsection.5.2}% 24
\BOOKMARK [2][-]{subsection.5.3}{Computation Improvment}{section.5}% 25
\BOOKMARK [1][-]{section.6}{CNN Case studies}{}% 26
\BOOKMARK [2][-]{subsection.6.1}{Classic Networks}{section.6}% 27
\BOOKMARK [3][-]{subsubsection.6.1.1}{LeNet-5}{subsection.6.1}% 28
\BOOKMARK [3][-]{subsubsection.6.1.2}{AlexNet}{subsection.6.1}% 29
\BOOKMARK [3][-]{subsubsection.6.1.3}{VGG-16}{subsection.6.1}% 30
\BOOKMARK [2][-]{subsection.6.2}{ResNet}{section.6}% 31
\BOOKMARK [3][-]{subsubsection.6.2.1}{Introduction}{subsection.6.2}% 32
\BOOKMARK [3][-]{subsubsection.6.2.2}{Intuition}{subsection.6.2}% 33
\BOOKMARK [2][-]{subsection.6.3}{1*1 convolution}{section.6}% 34
\BOOKMARK [2][-]{subsection.6.4}{Inception Network}{section.6}% 35
\BOOKMARK [2][-]{subsection.6.5}{Pratical Advices}{section.6}% 36
\BOOKMARK [3][-]{subsubsection.6.5.1}{Data Augmentation}{subsection.6.5}% 37
\BOOKMARK [3][-]{subsubsection.6.5.2}{Deep Learning for Computer Vision}{subsection.6.5}% 38
\BOOKMARK [1][-]{section.7}{Detection Algorithm}{}% 39
\BOOKMARK [2][-]{subsection.7.1}{Object Location}{section.7}% 40
\BOOKMARK [2][-]{subsection.7.2}{Convolutional Implementation of Sliding Windows}{section.7}% 41
\BOOKMARK [2][-]{subsection.7.3}{YOLO Algorithm}{section.7}% 42
\BOOKMARK [2][-]{subsection.7.4}{Intersection Over Union}{section.7}% 43
\BOOKMARK [2][-]{subsection.7.5}{Non-max Suppression}{section.7}% 44
\BOOKMARK [2][-]{subsection.7.6}{Anchor Boxes}{section.7}% 45
\BOOKMARK [1][-]{section.8}{Special Applications}{}% 46
\BOOKMARK [2][-]{subsection.8.1}{Face Recognition}{section.8}% 47
\BOOKMARK [3][-]{subsubsection.8.1.1}{Face verification}{subsection.8.1}% 48
\BOOKMARK [3][-]{subsubsection.8.1.2}{Nerual Network For Degree Difference - Siamese Network}{subsection.8.1}% 49
\BOOKMARK [3][-]{subsubsection.8.1.3}{Triplet Loss}{subsection.8.1}% 50
\BOOKMARK [3][-]{subsubsection.8.1.4}{Binary Classification}{subsection.8.1}% 51
\BOOKMARK [2][-]{subsection.8.2}{Neural Style Transfer}{section.8}% 52
\BOOKMARK [1][-]{section.9}{Recurrent Neural Networks \(RNN\)}{}% 53
\BOOKMARK [2][-]{subsection.9.1}{Practical Example}{section.9}% 54
\BOOKMARK [2][-]{subsection.9.2}{Image Captioning}{section.9}% 55
\BOOKMARK [2][-]{subsection.9.3}{LSTM}{section.9}% 56
\BOOKMARK [2][-]{subsection.9.4}{Variants on LSTMs}{section.9}% 57
\BOOKMARK [2][-]{subsection.9.5}{Difference between RNN and LSTM}{section.9}% 58
\BOOKMARK [2][-]{subsection.9.6}{Bidirectional RNN}{section.9}% 59
\BOOKMARK [2][-]{subsection.9.7}{Summary}{section.9}% 60
\BOOKMARK [1][-]{section.10}{Attention Models}{}% 61
\BOOKMARK [2][-]{subsection.10.1}{Soft Attention for Captioning}{section.10}% 62
\BOOKMARK [2][-]{subsection.10.2}{Soft vs Hard Attention}{section.10}% 63
\BOOKMARK [2][-]{subsection.10.3}{Recap}{section.10}% 64
\BOOKMARK [1][-]{section.11}{Generative Adversarial Nets \(GAN\)}{}% 65
\BOOKMARK [2][-]{subsection.11.1}{Examples}{section.11}% 66
\BOOKMARK [1][-]{section.12}{Reinforcement Learning Basic Model}{}% 67
\BOOKMARK [2][-]{subsection.12.1}{Information State}{section.12}% 68
\BOOKMARK [2][-]{subsection.12.2}{Observability}{section.12}% 69
\BOOKMARK [2][-]{subsection.12.3}{Components of RL agent}{section.12}% 70
\BOOKMARK [2][-]{subsection.12.4}{Learning and Planning}{section.12}% 71
\BOOKMARK [1][-]{section.13}{Markov Decision Process}{}% 72
\BOOKMARK [2][-]{subsection.13.1}{Introduction to MDP}{section.13}% 73
\BOOKMARK [2][-]{subsection.13.2}{Markov Decision Process}{section.13}% 74
\BOOKMARK [2][-]{subsection.13.3}{Infinite MDPs}{section.13}% 75
